// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

#if swift(>=5.5) && canImport(_Concurrency)
@available(macOS 12.0, iOS 15.0, tvOS 15.0, watchOS 8.0, macCatalyst 15.0, *)
public extension PollyClient {
    /// Deletes the specified pronunciation lexicon stored in an Amazon Web Services Region. A lexicon which has been deleted is not available for speech synthesis, nor is it possible to retrieve it using either the GetLexicon or ListLexicon APIs. For more information, see [Managing Lexicons](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).
    func deleteLexicon(input: DeleteLexiconInput) async throws -> DeleteLexiconOutputResponse
    {
        typealias deleteLexiconContinuation = CheckedContinuation<DeleteLexiconOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: deleteLexiconContinuation) in
            deleteLexicon(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Returns the list of voices that are available for use when requesting speech synthesis. Each voice speaks a specified language, is either male or female, and is identified by an ID, which is the ASCII version of the voice name. When synthesizing speech ( SynthesizeSpeech ), you provide the voice ID for the voice you want from the list of voices returned by DescribeVoices. For example, you want your news reader application to read news in a specific language, but giving a user the option to choose the voice. Using the DescribeVoices operation you can provide the user with a list of available voices to select from. You can optionally specify a language code to filter the available voices. For example, if you specify en-US, the operation returns a list of all available US English voices. This operation requires permissions to perform the polly:DescribeVoices action.
    func describeVoices(input: DescribeVoicesInput) async throws -> DescribeVoicesOutputResponse
    {
        typealias describeVoicesContinuation = CheckedContinuation<DescribeVoicesOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: describeVoicesContinuation) in
            describeVoices(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Returns the content of the specified pronunciation lexicon stored in an Amazon Web Services Region. For more information, see [Managing Lexicons](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).
    func getLexicon(input: GetLexiconInput) async throws -> GetLexiconOutputResponse
    {
        typealias getLexiconContinuation = CheckedContinuation<GetLexiconOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: getLexiconContinuation) in
            getLexicon(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Retrieves a specific SpeechSynthesisTask object based on its TaskID. This object contains information about the given speech synthesis task, including the status of the task, and a link to the S3 bucket containing the output of the task.
    func getSpeechSynthesisTask(input: GetSpeechSynthesisTaskInput) async throws -> GetSpeechSynthesisTaskOutputResponse
    {
        typealias getSpeechSynthesisTaskContinuation = CheckedContinuation<GetSpeechSynthesisTaskOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: getSpeechSynthesisTaskContinuation) in
            getSpeechSynthesisTask(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Returns a list of pronunciation lexicons stored in an Amazon Web Services Region. For more information, see [Managing Lexicons](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).
    func listLexicons(input: ListLexiconsInput) async throws -> ListLexiconsOutputResponse
    {
        typealias listLexiconsContinuation = CheckedContinuation<ListLexiconsOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: listLexiconsContinuation) in
            listLexicons(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Returns a list of SpeechSynthesisTask objects ordered by their creation date. This operation can filter the tasks by their status, for example, allowing users to list only tasks that are completed.
    func listSpeechSynthesisTasks(input: ListSpeechSynthesisTasksInput) async throws -> ListSpeechSynthesisTasksOutputResponse
    {
        typealias listSpeechSynthesisTasksContinuation = CheckedContinuation<ListSpeechSynthesisTasksOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: listSpeechSynthesisTasksContinuation) in
            listSpeechSynthesisTasks(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Stores a pronunciation lexicon in an Amazon Web Services Region. If a lexicon with the same name already exists in the region, it is overwritten by the new lexicon. Lexicon operations have eventual consistency, therefore, it might take some time before the lexicon is available to the SynthesizeSpeech operation. For more information, see [Managing Lexicons](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).
    func putLexicon(input: PutLexiconInput) async throws -> PutLexiconOutputResponse
    {
        typealias putLexiconContinuation = CheckedContinuation<PutLexiconOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: putLexiconContinuation) in
            putLexicon(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Allows the creation of an asynchronous synthesis task, by starting a new SpeechSynthesisTask. This operation requires all the standard information needed for speech synthesis, plus the name of an Amazon S3 bucket for the service to store the output of the synthesis task and two optional parameters (OutputS3KeyPrefix and SnsTopicArn). Once the synthesis task is created, this operation will return a SpeechSynthesisTask object, which will include an identifier of this task as well as the current status. The SpeechSynthesisTask object is available for 72 hours after starting the asynchronous synthesis task.
    func startSpeechSynthesisTask(input: StartSpeechSynthesisTaskInput) async throws -> StartSpeechSynthesisTaskOutputResponse
    {
        typealias startSpeechSynthesisTaskContinuation = CheckedContinuation<StartSpeechSynthesisTaskOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: startSpeechSynthesisTaskContinuation) in
            startSpeechSynthesisTask(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Synthesizes UTF-8 input, plain text or SSML, to a stream of bytes. SSML input must be valid, well-formed SSML. Some alphabets might not be available with all the voices (for example, Cyrillic might not be read at all by English voices) unless phoneme mapping is used. For more information, see [How it Works](https://docs.aws.amazon.com/polly/latest/dg/how-text-to-speech-works.html).
    func synthesizeSpeech(input: SynthesizeSpeechInput) async throws -> SynthesizeSpeechOutputResponse
    {
        typealias synthesizeSpeechContinuation = CheckedContinuation<SynthesizeSpeechOutputResponse, Swift.Error>
        return try await withCheckedThrowingContinuation { (continuation: synthesizeSpeechContinuation) in
            synthesizeSpeech(input: input) { result in
                switch result {
                    case .success(let output):
                        continuation.resume(returning: output)
                    case .failure(let error):
                        continuation.resume(throwing: error)
                }
            }
        }
    }

}
#endif
